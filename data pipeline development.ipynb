{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c973caf-2a65-4e3f-8ea1-fe8c921475dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf0ddb3-7f1a-4f3c-8a71-ac70b9216238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- STEP 1: DATA EXTRACTION -----------\n",
    "def fetch_data():\n",
    "    # For demonstration, let's create a small dataset from scratch\n",
    "    data = {\n",
    "        'Name': ['Pavan tej', 'Gowtham', 'Naveen', 'Santosh', 'Siddhu'],\n",
    "        'Age': [25, np.nan, 35, 29, 42],\n",
    "        'City': ['Rajam', 'Banglore', 'Khammam', np.nan, 'Warangal'],\n",
    "        'Salary': [70000, 80000, np.nan, 65000, 90000]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Initial Data:\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e271e1f6-ec83-40fe-a47c-c50f154bb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    # Define your feature lists first\n",
    "    numeric_features = ['Age', 'Salary']\n",
    "    categorical_features = ['City']\n",
    "\n",
    "    # Now you can use them\n",
    "    features = numeric_features + categoric# ----------- STEP 1: DATA EXTRACTION -----------\n",
    "def fetch_data():\n",
    "    # For demonstration, let's create a small dataset from scratch\n",
    "    data = {\n",
    "        'Name': ['Pavan tej', 'Gowtham', 'Naveen', 'Santosh', 'Siddhu'],\n",
    "        'Age': [25, np.nan, 35, 29, 42],\n",
    "        'City': ['Rajam', 'Banglore', 'Khammam', np.nan, 'Warangal'],\n",
    "        'Salary': [70000, 80000, np.nan, 65000, 90000]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Initial Data:\")\n",
    "    print(df)\n",
    "    return dfal_features\n",
    "\n",
    "    # Define your pipelines\n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='median')),\n",
    "        ('scale', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "        ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformations\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    transformed_data = preprocessor.fit_transform(df[features])\n",
    "\n",
    "    # Get new column names after transformation\n",
    "    cat_columns = preprocessor.named_transformers_['cat']['encode'].get_feature_names_out(categorical_features)\n",
    "    all_columns = numeric_features + list(cat_columns)\n",
    "\n",
    "    # Convert to DataFrame for easy viewing\n",
    "    transformed_df = pd.DataFrame(transformed_data, columns=all_columns)\n",
    "    print(\"\\nTransformed Data:\")\n",
    "    print(transformed_df)\n",
    "    return transformed_df, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c65088b6-528a-4869-9e99-4aa4aa465f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- STEP 3: DATA LOADING -----------\n",
    "def load_data(transformed_df, filename='processed_data.csv'):\n",
    "    # Save the processed data to a CSV file\n",
    "    transformed_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nProcessed data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d051631-5d8b-4470-8c37-02d2e813b7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data:\n",
      "        Name   Age      City   Salary\n",
      "0  Pavan tej  25.0     Rajam  70000.0\n",
      "1    Gowtham   NaN  Banglore  80000.0\n",
      "2     Naveen  35.0   Khammam      NaN\n",
      "3    Santosh  29.0       NaN  65000.0\n",
      "4     Siddhu  42.0  Warangal  90000.0\n",
      "\n",
      "Transformed Data:\n",
      "        Age    Salary  City_Banglore  City_Khammam  City_Rajam  City_Unknown  \\\n",
      "0 -1.322189 -0.697486            0.0           0.0         1.0           0.0   \n",
      "1 -0.104383  0.464991            1.0           0.0         0.0           0.0   \n",
      "2  0.417533 -0.116248            0.0           1.0         0.0           0.0   \n",
      "3 -0.626300 -1.278724            0.0           0.0         0.0           1.0   \n",
      "4  1.635339  1.627467            0.0           0.0         0.0           0.0   \n",
      "\n",
      "   City_Warangal  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            1.0  \n",
      "\n",
      "Processed data saved to processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------- MAIN PIPELINE EXECUTION -----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract\n",
    "    df = fetch_data()\n",
    "    \n",
    "    # Transform\n",
    "    processed_df, transformer = transform_data(df)\n",
    "    \n",
    "    # Load\n",
    "    load_data(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5264d257-a378-459b-bf2b-4950a391696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformer saved for future use as 'transformer.joblib'.\n"
     ]
    }
   ],
   "source": [
    "    # Optionally, save the transformer for future use (e.g., in a real ML pipeline)\n",
    "    joblib.dump(transformer, \"transformer.joblib\")\n",
    "    print(\"\\nTransformer saved for future use as 'transformer.joblib'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae80fa-e043-444c-9bda-8e58bc14586a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74758b08-1c9d-4210-914a-918deb51c2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
